function Answer = NPCG(InitialGuess,Kernel1,Kernel2,Signal,Lambdas,r1,r2,options,handles)

%Define algorithm stop requirements
ToleranceFactor = options.TolFun;
IterationMax = options.MaxEval;

Answer=InitialGuess;
[Nx,Ny]=size(InitialGuess);
options.plotall=1;
L2 = get_l(Nx^2,2); 
% Lambdas = (Lambdas.*Lambdas').^0.5;
%Run NP-algorithm for a maximum Iterations
for Iteration=1:IterationMax
  
  if strcmp(options.StepSizeMethod,'armijo')
    Lambdas = Lambdas/max(max((Lambdas)));
    % SD requires no normalization
    % Armijo requires normalization
  end

%----------------Prepare objective function & gradient---------------------
  
% Compute current objective function
ObjectiveError = 0.5*norm(Kernel1*Answer*Kernel2'-Signal)^2  + sum(sum(Lambdas.*reshape(L2*reshape(Answer,[],1).^2,Nx,Nx))) ;
% Compute gradient matrix of objective function
Gradient = (Kernel1'*(Kernel1*Answer*Kernel2'-Signal)*Kernel2) + Lambdas.*reshape(L2'*(L2*reshape(Answer,[],1)),Nx,Nx);
% Normalize
%   normFactor = Kernel1'*(Kernel1*Kernel2')*Kernel2;
%   Gradient = Gradient./normFactor;
  Gradient = reshape(Gradient,[],1);
% Compute Hessian matrix of objective function
% Hessian = kron(Kernel1*Kernel1', Kernel2*Kernel2') ;%+  Lambdas*(L'*L) ;
% Hessian = gradient(reshape((Kernel1'*(Kernel1*Answer*Kernel2'-Signal)*Kernel2)./(Kernel1'*(Kernel1*Kernel2')*Kernel2),[],1)) + reshape(Lambdas*(L'*L),[],1);
% S = diag(reshape(Signal./(Kernel1*Answer*Kernel2').^2,[],1));
Hessian = kron(Kernel2',Kernel1')*kron(Kernel2,Kernel1) + reshape(Lambdas,[],1).*(L2'*L2);
% Hessian = Gradient*L2 + reshape(Lambdas,[],1).*(L2'*L2);

%   normFactor = Kernel1'*(Kernel1*Kernel2')*Kernel2;

   Answer = reshape(Answer,[],1);

   epsbar=1e-12;
   % Compute epsilon parameter
   epsilon = sum(Answer-posorth((Answer-Gradient)));
   if epsbar < epsilon
      epsilon = epsbar; 
   end
   %Get subset of indices with non-negative gradient
   SubSet1 = find(Gradient > 0);
   %Get subset of indices with answer between 0 and epsilon
   SubSet2 = find(Answer(SubSet1) >= 0 & Answer(SubSet1) <= epsilon);
   
   % Build diagonal matrix with respect to subset 2
   E=eye(length(Gradient),length(Gradient));
   for i=1:length(SubSet2)
     pos = SubSet2(i);
     E(pos,pos)=0;
   end
   D=eye(length(Gradient),length(Gradient))-E;
   
   % Construct step direction vector
   Lambdas = reshape(Lambdas,[],1);
   DirectionVector = Lambdas;
   DirectionVector=conjgrad(E*Hessian*E+D,-Gradient,1e-6);
%    nu = zeros(length(Hessian),1);
%    nu=conjgrad(Hessian,(E*Gradient),nu);
%    DirectionVector = E*nu + D*Gradient; 
%    DirectionVector = linsolve(E.*Hessian.*E+D,-Gradient);
%    DirectionVector(DirectionVector<0)=0;
%    DirectionVector(SubSet2) = Gradient(SubSet2); 
   DirectionVector(isnan(DirectionVector))= 0;
   figure(12),pcolor(reshape(DirectionVector,Nx,Nx)),shading flat
%    ScalingMatrix = E.*diag(Lambdas);
ScalingMatrix = E*Hessian*E+D;
%    DirectionVector = DirectionVector.*Lambdas';
%----------------------------Determine step size------------------------------ 
   switch options.StepSizeMethod
     
     case 'sd'  %Scaled Steepest Descent (SD) step size
       
       alpha = Gradient'*ScalingMatrix*Gradient/((norm(reshape((Kernel1*reshape(ScalingMatrix'*Gradient,Nx,Nx)*Kernel2'),[],1))));
       
     case 'mg' %Scaled Minimal Gradient (MG) step size
       
      alpha = Gradient'*ScalingMatrix*reshape(Kernel1'*(Kernel1*reshape(Gradient,Nx,Nx)*Kernel2')*Kernel2,[],1)/(norm((Kernel1'*(Kernel1*reshape(ScalingMatrix'*Gradient,Nx,Nx)*Kernel2')*Kernel2)));
       
     case 'abbs' % Adaptive Barzilai-Borwein (ABB) step size
       
       tau = 0.4;
       Answer = reshape(Answer,Nx,Nx);
       Lambdas = reshape(Lambdas,Nx,Nx);
       AnswerDifference = reshape(Answer - InitialGuess,[],1);
       PreviousGradient = reshape((Kernel1'*(Kernel1*InitialGuess*Kernel2' - Signal)*Kernel2),[],1) + reshape(Lambdas.*gradient(gradient(Answer))',[],1);
       Lambdas = reshape(Lambdas,[],1);
       GradientDifference = Gradient - PreviousGradient;
       %Compute Barzilai-Borwein 1 Scaled (BB1S) stepsize
       alphaBBS1 = abs(AnswerDifference'*(E.*Lambdas)*AnswerDifference./(GradientDifference'*(E.*Lambdas)*(E.*Lambdas)*AnswerDifference));
       %Compute Barzilai-Borwein 2 Scaled (BB2S) stepsize
       alphaBBS2 = abs(AnswerDifference'*((E.*Lambdas)^(-1))*((E.*Lambdas)^(-1))*GradientDifference./(GradientDifference'*((E.*Lambdas)^(-1))*GradientDifference));
       alphaBBS1(isnan(alphaBBS1)) = 0;
       alphaBBS2(isnan(alphaBBS2)) = 0;
       % Check switching criterion
       if alphaBBS2/alphaBBS1 < tau
         alpha  = alphaBBS2;
       else
         alpha = alphaBBS1;
       end
       
       alphamin = 0.1;
       if alpha < alphamin
         alpha = alphamin;
       end
       
     case 'armijo' % Armijo's rule for stepsize
       
       
       % Parameters Armijo's rule
       beta= options.ArmijoBasis;                  % Restricted to 0<beta<1
       z=options.ArmijoScale;                      % Restricted to z>0
       gamma=options.ArmijoPenalty;                 % Restricted to 0<z<1
       alphamin = options.ArmijoMinimum;
       m = 0;
       alpha = beta^m*z;
       
       %----Compute new answer--------------------------------------------------
       Answer = reshape(Answer,[],1);
       Lambdas = reshape(Lambdas,Nx,Ny);
       NewAnswer = (Answer + alpha*DirectionVector);
       NewAnswer = reshape(NewAnswer,Nx,Ny);
       % Normalize
       normFactor = abs(Kernel1*NewAnswer*Kernel2');
       NewAnswer = NewAnswer/normFactor(1,1);
       
       NewError = 0.5*norm(Kernel1*(NewAnswer)*Kernel2' - Signal)^2 + sum(sum(Lambdas.*(L2*reshape(Answer,[],1)).^2));
       NewAnswer = reshape(NewAnswer,[],1);
       ObjectiveError = round(ObjectiveError,10);
       %------------------------------------------------------------------------
       Lambdas = reshape(Lambdas,[],1);
       
       while (ObjectiveError-NewError) < gamma*(alpha*sum(E*Gradient.*DirectionVector) + sum(D.*Gradient*((Answer + alpha*DirectionVector))))
         m = m + 1;
         alpha = round(beta^m*z,10); %round alpha to zero at very low values
         
         %----Compute new answer & Corresponding error--------------------------
         NewAnswer = (Answer + alpha*DirectionVector);
         NewAnswer = reshape(NewAnswer,Nx,Ny);
         % Normalize
         normFactor = (Kernel1*NewAnswer*Kernel2');
         NewAnswer = NewAnswer/normFactor(1,1);
         
         NewError = round(0.5*norm(Kernel1*(NewAnswer)*Kernel2' - Signal)^2,10) + sum(sum(Lambdas.*(L2*reshape(Answer,[],1)).^2));
         NewAnswer = reshape(NewAnswer,[],1);
         %----------------------------------------------------------------------
         if alpha < alphamin
           alpha = alphamin;
           break;
         end
       end
       
     case 'gauchy' %Gauchy Steep Descent step size-------------------------------
       
      alpha = Gradient'*Gradient/(Gradient'*reshape((Kernel1*reshape(Gradient,Nx,Nx)*Kernel2'),[],1)); 
      
   end
   
   %----Compute new answer--------------------------------------------------
   Answer = reshape(Answer,[],1);
   Lambdas = reshape(Lambdas,Nx,Ny);

   NewAnswer = (Answer + alpha*DirectionVector);
   NewAnswer = reshape(NewAnswer,Nx,Ny);
%      Normalize
   normFactor = abs(Kernel1*NewAnswer*Kernel2');
   NewAnswer = NewAnswer/normFactor(1,1);
   
   NewError = 0.5*norm(Kernel1*(NewAnswer)*Kernel2' - Signal)^2 + sum(sum(Lambdas.*(L2*reshape(Answer,[],1)).^2));
   NewAnswer = reshape(NewAnswer,[],1);
   ObjectiveError = round(ObjectiveError,10);
   %------------------------------------------------------------------------
   
   
       % Store employed alpha values for debugging
       alphas(Iteration) = alpha;

%--------------Projection into positive orthant----------------------------

%Construct diagonal matrix and find negative entries in new answer
D = zeros(Nx^2,Nx^2);
for i = 1:length(NewAnswer)
  if NewAnswer(i) >= 0
    D(i,i) = 1;
  end
end

%Store previous answer as initial guess
InitialGuess = Answer;
InitialGuess = reshape(InitialGuess,Nx,Nx);
% Project into positive orthant, assuming constant linesearch mu=1
Answer = D*NewAnswer;

%-------------------------Finish iteration---------------------------------
% Reshape definitive answers for this iteration
Answer = reshape(Answer,Nx,Ny);
NewAnswer = reshape(NewAnswer,Nx,Ny);

% Normalize
normFactor = abs(Kernel1*Answer*Kernel2');
Answer = Answer/normFactor(1,1);


for i=1:2
    Answer(i,:) = 0;
    Answer(:,i) = 0;
    Answer(Nx-i+1,:) = 0;
    Answer(:,Nx-i+1) = 0;
end

% Get definitive error for this iteration
NewError = 0.5*norm(Kernel1*(Answer)*Kernel2'-Signal)^2 + sum(sum(Lambdas.*(L2*reshape(Answer,[],1)).^2));

switch options.EvalFun
  case 1  % Relative Error Difference
    EvalFun(Iteration) = (ObjectiveError-NewError)/ObjectiveError;
    
  case 2  % Relative Answer Difference
    EvalFun(Iteration) = norm(InitialGuess-Answer)/norm(InitialGuess);
    
  case 3  % Objective Error
    EvalFun(Iteration) = NewError;
end
%Display algorithm status on console
info = sprintf('NPCG Iter=%d Eval=%f',Iteration, EvalFun(Iteration));
disp(info);


colormap jet
pcolor(handles.RegularizedPlot,r1,r2,Answer)
xlabel(handles.RegularizedPlot,'r_1 [nm]')
ylabel(handles.RegularizedPlot,'r_2 [nm]')
drawnow
hold(handles.ConvergencePlot,'on')
plot(handles.ConvergencePlot,1:length(EvalFun),(EvalFun),'ko'),drawnow
hold(handles.ConvergencePlot,'on')
drawnow

   % Stop if convergence of evalutaion function satisfies condition or is stopped
   if get(handles.StopButton,'userdata') || abs(EvalFun(Iteration))<ToleranceFactor % stop condition
     break;
   end

end
